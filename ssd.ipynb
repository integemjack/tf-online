{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "788n7BqZKMda",
        "outputId": "54c6373b-6a1c-49cd-de3e-7ebd5e01516e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/dusty-nv/pytorch-ssd.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yusLHocNL8pM",
        "outputId": "110b1458-8796-47c7-9ede-e44bad91fa10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-ssd'...\n",
            "remote: Enumerating objects: 1004, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 1004 (delta 49), reused 63 (delta 37), pack-reused 919\u001b[K\n",
            "Receiving objects: 100% (1004/1004), 1.11 MiB | 19.22 MiB/s, done.\n",
            "Resolving deltas: 100% (655/655), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls\n",
        "%cd pytorch-ssd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKE3apS_MDXA",
        "outputId": "1a092f94-2b1f-41c3-9d4b-9144252ce229"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch-ssd  sample_data\n",
            "/content/pytorch-ssd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLalhTqiMLpS",
        "outputId": "aa058385-fd65-4b50-e3d6-e7ecc33952de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t     onnx_export.py\t\trequirements.txt\n",
            "eval_ssd.py  open_images_classes.txt\trun_ssd_example.py\n",
            "LICENSE      open_images_downloader.py\ttrain_ssd.py\n",
            "models\t     README.md\t\t\tvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install boto3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS9kpR1zMYwA",
        "outputId": "ac6b0b3c-8400-4e78-d5df-591524dadf5a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.155-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.155 (from boto3)\n",
            "  Downloading botocore-1.29.155-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.155->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.30.0,>=1.29.155->boto3) (1.26.15)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.155->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.155 botocore-1.29.155 jmespath-1.0.1 s3transfer-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 open_images_downloader.py --class-names \"Apple,Orange,Banana,Strawberry,Grape,Pear,Pineapple,Watermelon\" --data=data/fruit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFCosjUMVZO",
        "outputId": "2df0f370-450f-4533-b3bd-a4382b132f19"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 10:57:15 - Download https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv.\n",
            "2023-06-19 10:57:15 - Requested 8 classes, found 8 classes\n",
            "2023-06-19 10:57:15 - Download https://storage.googleapis.com/openimages/2018_04/train/train-annotations-bbox.csv.\n",
            "2023-06-19 10:57:22 - Read annotation file data/fruit/train-annotations-bbox.csv\n",
            "2023-06-19 10:57:39 - Available train images:  5145\n",
            "2023-06-19 10:57:39 - Available train boxes:   23539\n",
            "\n",
            "2023-06-19 10:57:39 - Download https://storage.googleapis.com/openimages/2018_04/validation/validation-annotations-bbox.csv.\n",
            "2023-06-19 10:57:39 - Read annotation file data/fruit/validation-annotations-bbox.csv\n",
            "2023-06-19 10:57:40 - Available validation images:  285\n",
            "2023-06-19 10:57:40 - Available validation boxes:   825\n",
            "\n",
            "2023-06-19 10:57:40 - Download https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv.\n",
            "2023-06-19 10:57:40 - Read annotation file data/fruit/test-annotations-bbox.csv\n",
            "2023-06-19 10:57:41 - Available test images:  930\n",
            "2023-06-19 10:57:41 - Available test boxes:   2824\n",
            "\n",
            "2023-06-19 10:57:41 - Total available images: 6360\n",
            "2023-06-19 10:57:41 - Total available boxes:  27188\n",
            "\n",
            "\n",
            "-------------------------------------\n",
            " 'train' set statistics\n",
            "-------------------------------------\n",
            "  Image count:  5145\n",
            "  Bounding box count:  23539\n",
            "  Bounding box distribution: \n",
            "    Strawberry:  7553/23539 = 0.32\n",
            "    Orange:  6186/23539 = 0.26\n",
            "    Apple:  3622/23539 = 0.15\n",
            "    Grape:  2560/23539 = 0.11\n",
            "    Banana:  1574/23539 = 0.07\n",
            "    Pear:  757/23539 = 0.03\n",
            "    Watermelon:  753/23539 = 0.03\n",
            "    Pineapple:  534/23539 = 0.02\n",
            " \n",
            "\n",
            "-------------------------------------\n",
            " 'validation' set statistics\n",
            "-------------------------------------\n",
            "  Image count:  285\n",
            "  Bounding box count:  825\n",
            "  Bounding box distribution: \n",
            "    Strawberry:  326/825 = 0.40\n",
            "    Grape:  153/825 = 0.19\n",
            "    Orange:  148/825 = 0.18\n",
            "    Apple:  102/825 = 0.12\n",
            "    Watermelon:  31/825 = 0.04\n",
            "    Pineapple:  25/825 = 0.03\n",
            "    Banana:  22/825 = 0.03\n",
            "    Pear:  18/825 = 0.02\n",
            " \n",
            "\n",
            "-------------------------------------\n",
            " 'test' set statistics\n",
            "-------------------------------------\n",
            "  Image count:  930\n",
            "  Bounding box count:  2824\n",
            "  Bounding box distribution: \n",
            "    Orange:  826/2824 = 0.29\n",
            "    Strawberry:  754/2824 = 0.27\n",
            "    Grape:  446/2824 = 0.16\n",
            "    Apple:  329/2824 = 0.12\n",
            "    Banana:  132/2824 = 0.05\n",
            "    Watermelon:  125/2824 = 0.04\n",
            "    Pear:  107/2824 = 0.04\n",
            "    Pineapple:  105/2824 = 0.04\n",
            " \n",
            "\n",
            "-------------------------------------\n",
            " Overall statistics\n",
            "-------------------------------------\n",
            "  Image count:  6360\n",
            "  Bounding box count:  27188\n",
            "\n",
            "2023-06-19 10:57:41 - Saving 'train' data to data/fruit/sub-train-annotations-bbox.csv.\n",
            "2023-06-19 10:57:41 - Saving 'validation' data to data/fruit/sub-validation-annotations-bbox.csv.\n",
            "2023-06-19 10:57:41 - Saving 'test' data to data/fruit/sub-test-annotations-bbox.csv.\n",
            "2023-06-19 10:57:41 - Starting to download 6360 images.\n",
            "2023-06-19 10:57:44 - Downloaded 100 images.\n",
            "2023-06-19 10:57:46 - Downloaded 200 images.\n",
            "2023-06-19 10:57:48 - Downloaded 300 images.\n",
            "2023-06-19 10:57:50 - Downloaded 400 images.\n",
            "2023-06-19 10:57:53 - Downloaded 500 images.\n",
            "2023-06-19 10:57:55 - Downloaded 600 images.\n",
            "2023-06-19 10:57:57 - Downloaded 700 images.\n",
            "2023-06-19 10:57:59 - Downloaded 800 images.\n",
            "2023-06-19 10:58:01 - Downloaded 900 images.\n",
            "2023-06-19 10:58:03 - Downloaded 1000 images.\n",
            "2023-06-19 10:58:05 - Downloaded 1100 images.\n",
            "2023-06-19 10:58:07 - Downloaded 1200 images.\n",
            "2023-06-19 10:58:09 - Downloaded 1300 images.\n",
            "2023-06-19 10:58:11 - Downloaded 1400 images.\n",
            "2023-06-19 10:58:13 - Downloaded 1500 images.\n",
            "2023-06-19 10:58:16 - Downloaded 1600 images.\n",
            "2023-06-19 10:58:18 - Downloaded 1700 images.\n",
            "2023-06-19 10:58:20 - Downloaded 1800 images.\n",
            "2023-06-19 10:58:22 - Downloaded 1900 images.\n",
            "2023-06-19 10:58:24 - Downloaded 2000 images.\n",
            "2023-06-19 10:58:26 - Downloaded 2100 images.\n",
            "2023-06-19 10:58:28 - Downloaded 2200 images.\n",
            "2023-06-19 10:58:30 - Downloaded 2300 images.\n",
            "2023-06-19 10:58:32 - Downloaded 2400 images.\n",
            "2023-06-19 10:58:34 - Downloaded 2500 images.\n",
            "2023-06-19 10:58:36 - Downloaded 2600 images.\n",
            "2023-06-19 10:58:38 - Downloaded 2700 images.\n",
            "2023-06-19 10:58:40 - Downloaded 2800 images.\n",
            "2023-06-19 10:58:42 - Downloaded 2900 images.\n",
            "2023-06-19 10:58:44 - Downloaded 3000 images.\n",
            "2023-06-19 10:58:46 - Downloaded 3100 images.\n",
            "2023-06-19 10:58:48 - Downloaded 3200 images.\n",
            "2023-06-19 10:58:50 - Downloaded 3300 images.\n",
            "2023-06-19 10:58:52 - Downloaded 3400 images.\n",
            "2023-06-19 10:58:54 - Downloaded 3500 images.\n",
            "2023-06-19 10:58:57 - Downloaded 3600 images.\n",
            "2023-06-19 10:58:59 - Downloaded 3700 images.\n",
            "2023-06-19 10:59:01 - Downloaded 3800 images.\n",
            "2023-06-19 10:59:03 - Downloaded 3900 images.\n",
            "2023-06-19 10:59:05 - Downloaded 4000 images.\n",
            "2023-06-19 10:59:07 - Downloaded 4100 images.\n",
            "2023-06-19 10:59:09 - Downloaded 4200 images.\n",
            "2023-06-19 10:59:11 - Downloaded 4300 images.\n",
            "2023-06-19 10:59:13 - Downloaded 4400 images.\n",
            "2023-06-19 10:59:15 - Downloaded 4500 images.\n",
            "2023-06-19 10:59:17 - Downloaded 4600 images.\n",
            "2023-06-19 10:59:19 - Downloaded 4700 images.\n",
            "2023-06-19 10:59:21 - Downloaded 4800 images.\n",
            "2023-06-19 10:59:23 - Downloaded 4900 images.\n",
            "2023-06-19 10:59:25 - Downloaded 5000 images.\n",
            "2023-06-19 10:59:27 - Downloaded 5100 images.\n",
            "2023-06-19 10:59:29 - Downloaded 5200 images.\n",
            "2023-06-19 10:59:31 - Downloaded 5300 images.\n",
            "2023-06-19 10:59:33 - Downloaded 5400 images.\n",
            "2023-06-19 10:59:36 - Downloaded 5500 images.\n",
            "2023-06-19 10:59:38 - Downloaded 5600 images.\n",
            "2023-06-19 10:59:40 - Downloaded 5700 images.\n",
            "2023-06-19 10:59:42 - Downloaded 5800 images.\n",
            "2023-06-19 10:59:43 - Downloaded 5900 images.\n",
            "2023-06-19 10:59:46 - Downloaded 6000 images.\n",
            "2023-06-19 10:59:48 - Downloaded 6100 images.\n",
            "2023-06-19 10:59:50 - Downloaded 6200 images.\n",
            "2023-06-19 10:59:52 - Downloaded 6300 images.\n",
            "2023-06-19 10:59:56 - Task Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train_ssd.py --data=data/fruit --model-dir=models/fruit --batch-size=4 --epochs=30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VIL4-ggNVYg",
        "outputId": "4d3d52f5-4041-4c0a-83c6-27c8cff1829f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-19 10:59:58.744482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-19 11:00:00.133729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-19 11:00:02 - Using CUDA...\n",
            "2023-06-19 11:00:02 - Namespace(dataset_type='open_images', datasets=['data/fruit'], balance_data=False, net='mb1-ssd', resolution=300, freeze_base_net=False, freeze_net=False, mb2_width_mult=1.0, base_net=None, pretrained_ssd='models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, lr=0.01, momentum=0.9, weight_decay=0.0005, gamma=0.1, base_net_lr=0.001, extra_layers_lr=None, scheduler='cosine', milestones='80,100', t_max=100, batch_size=4, num_epochs=30, num_workers=2, validation_epochs=1, validation_mean_ap=False, debug_steps=10, use_cuda=True, checkpoint_folder='models/fruit', log_level='info')\n",
            "2023-06-19 11:00:11 - model resolution 300x300\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=19, shrinkage=16, box_sizes=SSDBoxSizes(min=60, max=105), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=10, shrinkage=32, box_sizes=SSDBoxSizes(min=105, max=150), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=5, shrinkage=64, box_sizes=SSDBoxSizes(min=150, max=195), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=3, shrinkage=100, box_sizes=SSDBoxSizes(min=195, max=240), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=2, shrinkage=150, box_sizes=SSDBoxSizes(min=240, max=285), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - SSDSpec(feature_map_size=1, shrinkage=300, box_sizes=SSDBoxSizes(min=285, max=330), aspect_ratios=[2, 3])\n",
            "2023-06-19 11:00:11 - Prepare training datasets.\n",
            "2023-06-19 11:00:11 - loading annotations from: data/fruit/sub-train-annotations-bbox.csv\n",
            "2023-06-19 11:00:11 - annotations loaded from:  data/fruit/sub-train-annotations-bbox.csv\n",
            "num images:  5145\n",
            "2023-06-19 11:00:14 - Dataset Summary:Number of Images: 5145\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tApple: 3622\n",
            "\tBanana: 1574\n",
            "\tGrape: 2560\n",
            "\tOrange: 6186\n",
            "\tPear: 757\n",
            "\tPineapple: 534\n",
            "\tStrawberry: 7553\n",
            "\tWatermelon: 753\n",
            "2023-06-19 11:00:14 - Stored labels into file models/fruit/labels.txt.\n",
            "2023-06-19 11:00:14 - Train dataset size: 5145\n",
            "2023-06-19 11:00:14 - Prepare Validation datasets.\n",
            "2023-06-19 11:00:14 - loading annotations from: data/fruit/sub-test-annotations-bbox.csv\n",
            "2023-06-19 11:00:14 - annotations loaded from:  data/fruit/sub-test-annotations-bbox.csv\n",
            "num images:  930\n",
            "2023-06-19 11:00:15 - Dataset Summary:Number of Images: 930\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tApple: 329\n",
            "\tBanana: 132\n",
            "\tGrape: 446\n",
            "\tOrange: 826\n",
            "\tPear: 107\n",
            "\tPineapple: 105\n",
            "\tStrawberry: 754\n",
            "\tWatermelon: 125\n",
            "2023-06-19 11:00:15 - Validation dataset size: 930\n",
            "2023-06-19 11:00:15 - Build network.\n",
            "2023-06-19 11:00:15 - Init from pretrained SSD models/mobilenet-v1-ssd-mp-0_675.pth\n",
            "models/mobilenet-v1 100%[===================>]  36.23M  9.12MB/s    in 4.0s    \n",
            "2023-06-19 11:00:21 - Took 6.05 seconds to load the model.\n",
            "2023-06-19 11:00:21 - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
            "2023-06-19 11:00:21 - Uses CosineAnnealingLR scheduler.\n",
            "2023-06-19 11:00:21 - Start training from epoch 0.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2023-06-19 11:00:33 - Epoch: 0, Step: 10/1287, Avg Loss: 13.5464, Avg Regression Loss 4.2143, Avg Classification Loss: 9.3321\n",
            "2023-06-19 11:00:37 - Epoch: 0, Step: 20/1287, Avg Loss: 8.7010, Avg Regression Loss 3.3193, Avg Classification Loss: 5.3816\n",
            "2023-06-19 11:00:40 - Epoch: 0, Step: 30/1287, Avg Loss: 9.0805, Avg Regression Loss 3.6748, Avg Classification Loss: 5.4057\n",
            "2023-06-19 11:00:43 - Epoch: 0, Step: 40/1287, Avg Loss: 9.0894, Avg Regression Loss 4.0948, Avg Classification Loss: 4.9946\n",
            "2023-06-19 11:00:45 - Epoch: 0, Step: 50/1287, Avg Loss: 8.2944, Avg Regression Loss 3.2035, Avg Classification Loss: 5.0909\n",
            "2023-06-19 11:00:47 - Epoch: 0, Step: 60/1287, Avg Loss: 7.5892, Avg Regression Loss 2.9383, Avg Classification Loss: 4.6509\n",
            "2023-06-19 11:00:51 - Epoch: 0, Step: 70/1287, Avg Loss: 7.7729, Avg Regression Loss 2.7498, Avg Classification Loss: 5.0231\n",
            "2023-06-19 11:00:53 - Epoch: 0, Step: 80/1287, Avg Loss: 7.8675, Avg Regression Loss 2.9872, Avg Classification Loss: 4.8803\n",
            "2023-06-19 11:00:56 - Epoch: 0, Step: 90/1287, Avg Loss: 8.1435, Avg Regression Loss 2.9917, Avg Classification Loss: 5.1518\n",
            "2023-06-19 11:00:58 - Epoch: 0, Step: 100/1287, Avg Loss: 7.3464, Avg Regression Loss 2.6451, Avg Classification Loss: 4.7013\n",
            "2023-06-19 11:01:02 - Epoch: 0, Step: 110/1287, Avg Loss: 7.3263, Avg Regression Loss 2.5246, Avg Classification Loss: 4.8017\n",
            "2023-06-19 11:01:06 - Epoch: 0, Step: 120/1287, Avg Loss: 6.9505, Avg Regression Loss 2.4355, Avg Classification Loss: 4.5150\n",
            "2023-06-19 11:01:08 - Epoch: 0, Step: 130/1287, Avg Loss: 6.6677, Avg Regression Loss 2.2214, Avg Classification Loss: 4.4463\n",
            "2023-06-19 11:01:11 - Epoch: 0, Step: 140/1287, Avg Loss: 7.8546, Avg Regression Loss 3.1794, Avg Classification Loss: 4.6752\n",
            "2023-06-19 11:01:13 - Epoch: 0, Step: 150/1287, Avg Loss: 6.6834, Avg Regression Loss 2.3340, Avg Classification Loss: 4.3494\n",
            "2023-06-19 11:01:17 - Epoch: 0, Step: 160/1287, Avg Loss: 6.4609, Avg Regression Loss 2.1904, Avg Classification Loss: 4.2705\n",
            "2023-06-19 11:01:20 - Epoch: 0, Step: 170/1287, Avg Loss: 7.0501, Avg Regression Loss 2.4181, Avg Classification Loss: 4.6320\n",
            "2023-06-19 11:01:22 - Epoch: 0, Step: 180/1287, Avg Loss: 7.4044, Avg Regression Loss 2.6271, Avg Classification Loss: 4.7773\n",
            "2023-06-19 11:01:24 - Epoch: 0, Step: 190/1287, Avg Loss: 6.5876, Avg Regression Loss 2.2334, Avg Classification Loss: 4.3542\n",
            "2023-06-19 11:01:27 - Epoch: 0, Step: 200/1287, Avg Loss: 6.8175, Avg Regression Loss 2.3586, Avg Classification Loss: 4.4588\n",
            "2023-06-19 11:01:30 - Epoch: 0, Step: 210/1287, Avg Loss: 6.2368, Avg Regression Loss 2.0422, Avg Classification Loss: 4.1946\n",
            "2023-06-19 11:01:33 - Epoch: 0, Step: 220/1287, Avg Loss: 6.5749, Avg Regression Loss 2.1043, Avg Classification Loss: 4.4707\n",
            "2023-06-19 11:01:35 - Epoch: 0, Step: 230/1287, Avg Loss: 6.2315, Avg Regression Loss 1.9267, Avg Classification Loss: 4.3048\n"
          ]
        }
      ]
    }
  ]
}