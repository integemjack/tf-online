{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "788n7BqZKMda",
    "outputId": "54c6373b-6a1c-49cd-de3e-7ebd5e01516e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yusLHocNL8pM",
    "outputId": "110b1458-8796-47c7-9ede-e44bad91fa10",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/dusty-nv/pytorch-ssd.git\n",
    "%cd pytorch-ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLalhTqiMLpS",
    "outputId": "aa058385-fd65-4b50-e3d6-e7ecc33952de"
   },
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use demo training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HoFCosjUMVZO",
    "outputId": "2df0f370-450f-4533-b3bd-a4382b132f19"
   },
   "source": [
    "! python3 open_images_downloader.py --class-names \"Apple\" --data=data/fruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VIL4-ggNVYg",
    "outputId": "4d3d52f5-4041-4c0a-83c6-27c8cff1829f"
   },
   "source": [
    "! python3 train_ssd.py --data=data/fruit --model-dir=models/fruit --batch-size=4 --epochs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## If you have an nvidia graphics card on your computer and installed the latest driver, you can use this method to directly export the onnx file, or send it back to the nano to produce an onnx file\n",
    "! python3 onnx_export.py --model-dir=models/fruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use custom training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# jetson nano IP address\n",
    "os.environ[\"NANO\"] = \"192.168.20.80\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! apt update -y\n",
    "! apt install curl expect rsync -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -O ../rsync.sh https://raw.githubusercontent.com/integemjack/tf-online/main/rsync.sh\n",
    "! chmod +x ../rsync.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ../rsync.sh nvidia@$NANO:/home/nvidia/jetson-inference/python/training/detection/ssd/data/custom/* ./data/custom/ nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 train_ssd.py --dataset-type=voc --data=data/custom --model-dir=models/custom --workers=1 --batch-size=4 --epochs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## If you have an nvidia graphics card on your computer and installed the latest driver, you can use this method to directly export the onnx file, or send it back to the nano to produce an onnx file\n",
    "! python3 onnx_export.py --model-dir=models/custom\n",
    "! echo \"scp -r ./models/custom/xxx.onnx nvidia@$NANO:/home/nvidia/mqtt_ws/src/mqtt/models/\" | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ../rsync.sh ./models/custom/* nvidia@$NANO:/home/nvidia/jetson-inference/python/training/detection/ssd/models/custom/ nvidia"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
